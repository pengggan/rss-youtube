import os
import asyncio
import aiomysql
import logging
import datetime
from feedparser import parse
from dotenv import load_dotenv
from telegram.ext import Application, AIORateLimiter
import aiohttp

# 加载环境变量
load_dotenv()

# 初始化日志记录器
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# 四组 RSS 源列表
RSS_FEEDS_GROUP_1 = [
    'https://rsshub.app/zaobao/znews/china',
    'https://www.freedidi.com/feed'
]
RSS_FEEDS_GROUP_2 = [
    'https://rsshub.app/group2/feed1',
    'https://rsshub.app/group2/feed2'
]
RSS_FEEDS_GROUP_3 = [
    'https://rsshub.app/group3/feed1',
    'https://rsshub.app/group3/feed2'
]
RSS_FEEDS_GROUP_4 = ['https://rsshub.app/group4/feed1']  # 单独合并推送

# 从环境变量中获取配置
TELEGRAM_BOT_TOKEN_1 = os.getenv("TELEGRAM_BOT_TOKEN_1")
ALLOWED_CHAT_IDS_1 = os.getenv("ALLOWED_CHAT_IDS_1").split(",")

TELEGRAM_BOT_TOKEN_2 = os.getenv("TELEGRAM_BOT_TOKEN_2")
ALLOWED_CHAT_IDS_2 = os.getenv("ALLOWED_CHAT_IDS_2").split(",")

TELEGRAM_BOT_TOKEN_3 = os.getenv("TELEGRAM_BOT_TOKEN_3")
ALLOWED_CHAT_IDS_3 = os.getenv("ALLOWED_CHAT_IDS_3").split(",")

TELEGRAM_BOT_TOKEN_4 = os.getenv("TELEGRAM_BOT_TOKEN_4")
ALLOWED_CHAT_IDS_4 = os.getenv("ALLOWED_CHAT_IDS_4").split(",")

# 初始化Telegram应用和速率限制器
app_1 = Application.builder().token(TELEGRAM_BOT_TOKEN_1).rate_limiter(AIORateLimiter()).build()
app_2 = Application.builder().token(TELEGRAM_BOT_TOKEN_2).rate_limiter(AIORateLimiter()).build()
app_3 = Application.builder().token(TELEGRAM_BOT_TOKEN_3).rate_limiter(AIORateLimiter()).build()
app_4 = Application.builder().token(TELEGRAM_BOT_TOKEN_4).rate_limiter(AIORateLimiter()).build()

# 数据库表
TABLE_DEFINITIONS = {
    "sent_rss_group_1_2": """
        CREATE TABLE IF NOT EXISTS sent_rss_group_1_2 (
            id INT AUTO_INCREMENT PRIMARY KEY,
            url VARCHAR(255),
            subject VARCHAR(255),
            message_id VARCHAR(255),
            UNIQUE KEY unique_entry (url, subject, message_id)
        )
    """,
    "sent_rss_group_3": """
        CREATE TABLE IF NOT EXISTS sent_rss_group_3 (
            id INT AUTO_INCREMENT PRIMARY KEY,
            url VARCHAR(255),
            subject VARCHAR(255),
            message_id VARCHAR(255),
            UNIQUE KEY unique_entry (url, subject, message_id)
        )
    """,
    "sent_rss_group_4": """
        CREATE TABLE IF NOT EXISTS sent_rss_group_4 (
            id INT AUTO_INCREMENT PRIMARY KEY,
            url VARCHAR(255),
            subject VARCHAR(255),
            message_id VARCHAR(255),
            UNIQUE KEY unique_entry (url, subject, message_id)
        )
    """
}

# 定义一个并发限制器
MAX_CONCURRENT_REQUESTS = 5
semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)

# 异步数据库连接池
async def connect_to_db():
    try:
        pool = await aiomysql.create_pool(
            host=os.getenv("DB_HOST"),
            db=os.getenv("DB_NAME"),
            user=os.getenv("DB_USER"),
            password=os.getenv("DB_PASSWORD"),
            minsize=1,
            maxsize=10
        )
        await create_tables_if_not_exist(pool)
        return pool
    except Exception as e:
        logging.error(f"Error while connecting to MySQL: {e}")
        return None

async def create_tables_if_not_exist(pool):
    """检查并创建数据库表（如果不存在）。"""
    try:
        async with pool.acquire() as connection:
            async with connection.cursor() as cursor:
                for table_name, table_definition in TABLE_DEFINITIONS.items():
                    await cursor.execute(table_definition)
                    logging.info(f"Checked and ensured the existence of table {table_name}.")
    except Exception as e:
        logging.error(f"Error while checking or creating tables: {e}")

async def fetch_feed(session, feed):
    try:
        async with session.get(feed, timeout=60) as response:
            response.raise_for_status()
            content = await response.read()
            return parse(content)
    except Exception as e:
        logging.error(f"Error fetching {feed}: {e}")
        return None

async def send_message(bot, chat_id, text):
    try:
        await bot.send_message(chat_id=chat_id, text=text, parse_mode='Markdown')
        logging.info(f"Message sent to {chat_id}: {text}")
    except Exception as e:
        logging.error(f"Error sending message to {chat_id}: {e}")

async def process_feed_limited(session, feed, sent_entries, pool, chat_ids, bot, table_name, semaphore):
    async with semaphore:
        await process_feed(session, feed, sent_entries, pool, chat_ids, bot, table_name)

async def process_feed(session, feed, sent_entries, pool, chat_ids, bot, table_name):
    feed_data = await fetch_feed(session, feed)
    if feed_data is None:
        return []

    new_entries = []
    async with pool.acquire() as connection:
        async with connection.cursor() as cursor:
            for entry in feed_data.entries:
                subject = entry.title if entry.title else None
                url = entry.link if entry.link else None
                message_id = f"{subject}_{url}" if subject and url else None

                if (url, subject, message_id) not in sent_entries:
                    message = f"*{entry.title}*\n{entry.link}"
                    for chat_id in chat_ids:
                        await send_message(bot, chat_id, message)
                    new_entries.append((url, subject, message_id))

                    current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    await save_sent_entry_to_db(cursor, url if url else current_time, subject if subject else current_time, message_id if message_id else current_time, table_name)
                    sent_entries.add((url if url else current_time, subject if subject else current_time, message_id if message_id else current_time))

    return new_entries

async def load_sent_entries_from_db(pool, table_name):
    try:
        async with pool.acquire() as connection:
            async with connection.cursor() as cursor:
                await cursor.execute(f"SELECT url, subject, message_id FROM {table_name}")
                rows = await cursor.fetchall()
                return {(row[0], row[1], row[2]) for row in rows}
    except Exception as e:
        logging.error(f"Error fetching sent entries from {table_name}: {e}")
        return set()

async def save_sent_entry_to_db(cursor, url, subject, message_id, table_name):
    try:
        await cursor.execute(
            f"INSERT IGNORE INTO {table_name} (url, subject, message_id) VALUES (%s, %s, %s)",
            (url, subject, message_id)
        )
        logging.info(f"Saved sent entry: {url}, {subject}, {message_id} to {table_name}")
    except Exception as e:
        logging.error(f"Error saving sent entry to {table_name}: {e}")

# 定义JobQueue调度任务
async def schedule_feeds(app, feeds, interval):
    job_queue = app.job_queue
    for feed in feeds:
        job_queue.run_repeating(lambda context: process_feed_limited(context.session, feed, context.sent_entries, context.pool, context.chat_ids, context.bot, context.table_name, semaphore), interval=interval, first=0)

async def main():
    pool = await connect_to_db()
    if pool is None:
        logging.error("Failed to connect to the database. Exiting.")
        return

    async with aiohttp.ClientSession() as session:
        # 第一组和第二组共享一个数据库表
        sent_entries_1 = await load_sent_entries_from_db(pool, "sent_rss_group_1_2")
        tasks_1 = [process_feed_limited(session, feed, sent_entries_1, pool, ALLOWED_CHAT_IDS_1, app_1.bot, "sent_rss_group_1_2", semaphore) for feed in RSS_FEEDS_GROUP_1]
        tasks_2 = [process_feed_limited(session, feed, sent_entries_1, pool, ALLOWED_CHAT_IDS_2, app_2.bot, "sent_rss_group_1_2", semaphore) for feed in RSS_FEEDS_GROUP_2]

        # 第三组使用单独的数据库表
        sent_entries_2 = await load_sent_entries_from_db(pool, "sent_rss_group_3")
        tasks_3 = [process_feed_limited(session, feed, sent_entries_2, pool, ALLOWED_CHAT_IDS_3, app_3.bot, "sent_rss_group_3", semaphore) for feed in RSS_FEEDS_GROUP_3]

        # 第四组使用单独的数据库表，合并推送
        sent_entries_3 = await load_sent_entries_from_db(pool, "sent_rss_group_4")
        tasks_4 = [process_feed_limited(session, feed, sent_entries_3, pool, ALLOWED_CHAT_IDS_4, app_4.bot, "sent_rss_group_4", semaphore) for feed in RSS_FEEDS_GROUP_4]

        await asyncio.gather(*tasks_1, *tasks_2, *tasks_3, *tasks_4)

    pool.close()

if __name__ == "__main__":
    asyncio.run(main())
