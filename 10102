import os
import asyncio  
import aiomysql
import logging
import datetime
from feedparser import parse
from dotenv import load_dotenv
from telegram import Bot
from telegram.ext import Application, AIORateLimiter, JobQueue

# 加载环境变量
load_dotenv()

# 初始化日志记录器
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# 四组 RSS 源列表
RSS_FEEDS_GROUP_1 = [
    'https://rsshub.app/zaobao/znews/china', 
    'https://www.freedidi.com/feed'
]
RSS_FEEDS_GROUP_2 = [
    'https://rsshub.app/group2/feed1',
    'https://rsshub.app/group2/feed2'
]
RSS_FEEDS_GROUP_3 = [
    'https://rsshub.app/group3/feed1',
    'https://rsshub.app/group3/feed2'
]
RSS_FEEDS_GROUP_4 = ['https://rsshub.app/group4/feed1']  # 单独合并推送

# 从环境变量中获取配置
TELEGRAM_BOT_TOKEN_1 = os.getenv("TELEGRAM_BOT_TOKEN_1")
ALLOWED_CHAT_IDS_1 = os.getenv("ALLOWED_CHAT_IDS_1").split(",")

TELEGRAM_BOT_TOKEN_2 = os.getenv("TELEGRAM_BOT_TOKEN_2")
ALLOWED_CHAT_IDS_2 = os.getenv("ALLOWED_CHAT_IDS_2").split(",")

TELEGRAM_BOT_TOKEN_3 = os.getenv("TELEGRAM_BOT_TOKEN_3")
ALLOWED_CHAT_IDS_3 = os.getenv("ALLOWED_CHAT_IDS_3").split(",")

TELEGRAM_BOT_TOKEN_4 = os.getenv("TELEGRAM_BOT_TOKEN_4")
ALLOWED_CHAT_IDS_4 = os.getenv("ALLOWED_CHAT_IDS_4").split(",")

# 初始化Telegram应用和速率限制器
app_1 = Application.builder().token(TELEGRAM_BOT_TOKEN_1).rate_limiter(AIORateLimiter()).build()
app_2 = Application.builder().token(TELEGRAM_BOT_TOKEN_2).rate_limiter(AIORateLimiter()).build()
app_3 = Application.builder().token(TELEGRAM_BOT_TOKEN_3).rate_limiter(AIORateLimiter()).build()
app_4 = Application.builder().token(TELEGRAM_BOT_TOKEN_4).rate_limiter(AIORateLimiter()).build()

# 数据库表
DB_TABLE_1 = "sent_rss_group_1_2"
DB_TABLE_2 = "sent_rss_group_3"
DB_TABLE_3 = "sent_rss_group_4"  # 第四组单独使用

# 定义一个并发限制器
MAX_CONCURRENT_REQUESTS = 5
semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)

async def fetch_feed(session, feed):
    try:
        async with session.get(feed, timeout=60) as response:
            response.raise_for_status()
            content = await response.read()
            return parse(content)
    except Exception as e:
        logging.error(f"Error fetching {feed}: {e}")
        return None

async def send_message(bot, chat_id, text):
    try:
        await bot.send_message(chat_id=chat_id, text=text, parse_mode='Markdown')
        logging.info(f"Message sent to {chat_id}: {text}")
    except Exception as e:
        logging.error(f"Error sending message to {chat_id}: {e}")

async def process_feed_limited(session, feed, sent_entries, connection, chat_ids, bot, table_name, semaphore):
    async with semaphore:
        await process_feed(session, feed, sent_entries, connection, chat_ids, bot, table_name)

async def process_feed(session, feed, sent_entries, connection, chat_ids, bot, table_name):
    feed_data = await fetch_feed(session, feed)
    if feed_data is None:
        return []

    new_entries = []
    for entry in feed_data.entries:
        subject = entry.title if entry.title else None
        url = entry.link if entry.link else None
        message_id = f"{subject}_{url}" if subject and url else None

        if (url, subject, message_id) not in sent_entries:
            message = f"*{entry.title}*\n{entry.link}"
            for chat_id in chat_ids:
                await send_message(bot, chat_id, message)
            new_entries.append((url, subject, message_id))

            current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            await save_sent_entry_to_db(connection, url if url else current_time, subject if subject else current_time, message_id if message_id else current_time, table_name)
            sent_entries.add((url if url else current_time, subject if subject else current_time, message_id if message_id else current_time))
            await asyncio.sleep(6)

    return new_entries

async def connect_to_db():
    try:
        connection = await aiomysql.connect(
            host=os.getenv("DB_HOST"),
            db=os.getenv("DB_NAME"),
            user=os.getenv("DB_USER"),
            password=os.getenv("DB_PASSWORD")
        )
        return connection
    except Exception as e:
        logging.error(f"Error while connecting to MySQL: {e}")
        return None

async def load_sent_entries_from_db(connection, table_name):
    try:
        async with connection.cursor() as cursor:
            await cursor.execute(f"SELECT url, subject, message_id FROM {table_name}")
            rows = await cursor.fetchall()
            return {(row[0], row[1], row[2]) for row in rows}
    except Exception as e:
        logging.error(f"Error fetching sent entries from {table_name}: {e}")
        return set()

async def save_sent_entry_to_db(connection, url, subject, message_id, table_name):
    try:
        async with connection.cursor() as cursor:
            await cursor.execute(
                f"INSERT IGNORE INTO {table_name} (url, subject, message_id) VALUES (%s, %s, %s)", 
                (url, subject, message_id)
            )
            await connection.commit()
            logging.info(f"Saved sent entry: {url}, {subject}, {message_id} to {table_name}")
    except Exception as e:
        logging.error(f"Error saving sent entry to {table_name}: {e}")

# 定义JobQueue调度任务
async def schedule_feeds(app, feeds, interval):
    job_queue = app.job_queue
    for feed in feeds:
        job_queue.run_repeating(lambda context: process_feed_limited(context.session, feed, context.sent_entries, context.connection, context.chat_ids, context.bot, context.table_name, semaphore), interval=interval, first=0)

async def main():
    connection = await connect_to_db()
    if connection is None:
        logging.error("Failed to connect to the database. Exiting.")
        return

    async with aiohttp.ClientSession() as session:
        # 第一组和第二组共享一个数据库表
        sent_entries_1 = await load_sent_entries_from_db(connection, DB_TABLE_1)
        tasks_1 = [process_feed_limited(session, feed, sent_entries_1, connection, ALLOWED_CHAT_IDS_1, app_1.bot, DB_TABLE_1, semaphore) for feed in RSS_FEEDS_GROUP_1]
        tasks_2 = [process_feed_limited(session, feed, sent_entries_1, connection, ALLOWED_CHAT_IDS_2, app_2.bot, DB_TABLE_1, semaphore) for feed in RSS_FEEDS_GROUP_2]

        # 第三组使用单独的数据库表
        sent_entries_2 = await load_sent_entries_from_db(connection, DB_TABLE_2)
        tasks_3 = [process_feed_limited(session, feed, sent_entries_2, connection, ALLOWED_CHAT_IDS_3, app_3.bot, DB_TABLE_2, semaphore) for feed in RSS_FEEDS_GROUP_3]

        # 第四组使用单独的数据库表，合并推送
        sent_entries_3 = await load_sent_entries_from_db(connection, DB_TABLE_3)
        tasks_4 = [process_feed_limited(session, feed, sent_entries_3, connection, ALLOWED_CHAT_IDS_4, app_4.bot, DB_TABLE_3, semaphore) for feed in RSS_FEEDS_GROUP_4]

        await asyncio.gather(*tasks_1, *tasks_2, *tasks_3, *tasks_4)

    connection.close()

if __name__ == "__main__":
    asyncio.run(main())
